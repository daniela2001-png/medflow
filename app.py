# app.py
import gradio as gr
import requests
import os
from PIL import Image
import io
import time

HF_TOKEN = os.environ.get("HF_TOKEN")
API_URL = "https://api-inference.huggingface.co/models/google/medgemma-4b-it"

def analizar_imagen_api(imagen, tipo_analisis="Reporte Estructurado", idioma="EspaÃ±ol"):
    if imagen is None:
        return "âŒ Por favor carga una imagen primero", "", "Error: Sin imagen"
    
    try:
        inicio = time.time()
        
        print(f"ğŸ“¤ Enviando imagen a la API de Hugging Face...")
        
        # Convertir imagen a bytes
        buffered = io.BytesIO()
        imagen.save(buffered, format="PNG")
        img_bytes = buffered.getvalue()
        
        prompts = {
            "DescripciÃ³n General": "Describe esta imagen mÃ©dica identificando las estructuras anatÃ³micas visibles.",
            "Hallazgos PatolÃ³gicos": "Identifica cualquier hallazgo patolÃ³gico o anormal en esta imagen mÃ©dica.",
            "Reporte Estructurado": "Genera un reporte mÃ©dico estructurado con: TÃ‰CNICA, HALLAZGOS e IMPRESIÃ“N.",
            "DiagnÃ³stico Diferencial": "Proporciona un diagnÃ³stico diferencial basado en los hallazgos visibles."
        }
        
        prompt = prompts.get(tipo_analisis, prompts["Reporte Estructurado"])
        
        headers = {
            "Authorization": f"Bearer {HF_TOKEN}",
            "Content-Type": "application/json"
        }
        
        # Preparar payload (la API puede requerir formato especÃ­fico)
        # Intentamos con la imagen directamente primero
        response = requests.post(
            API_URL,
            headers={"Authorization": f"Bearer {HF_TOKEN}"},
            data=img_bytes,
            timeout=120
        )
        
        tiempo_parcial = time.time() - inicio
        
        if response.status_code == 200:
            try:
                resultado = response.json()
                print(f"âœ… Respuesta recibida: {resultado}")
                
                # Extraer texto de la respuesta
                if isinstance(resultado, list) and len(resultado) > 0:
                    if isinstance(resultado[0], dict):
                        reporte = resultado[0].get('generated_text', str(resultado))
                    else:
                        reporte = str(resultado[0])
                elif isinstance(resultado, dict):
                    reporte = resultado.get('generated_text', str(resultado))
                else:
                    reporte = str(resultado)
                
            except:
                reporte = response.text
            
            tiempo = time.time() - inicio
            
            disclaimer = """

âš ï¸ DISCLAIMER MÃ‰DICO:
Este reporte es generado por IA con propÃ³sito educativo y demostrativo Ãºnicamente.
NO debe utilizarse para decisiones clÃ­nicas sin validaciÃ³n por profesionales mÃ©dicos.
"""
            
            reporte_final = reporte + disclaimer
            
            metadata = f"""
ğŸ“Š **InformaciÃ³n de Procesamiento:**
- â±ï¸ Tiempo total: {tiempo:.2f} segundos
- ğŸ¤– Modelo: Med-GEMMA 4B (Google Health AI)
- ğŸ’» Procesamiento: Hugging Face Inference API con GPU
- ğŸŒ Tu Space: CPU basic (solo interfaz)
- ğŸ”§ Tipo anÃ¡lisis: {tipo_analisis}
"""
            
            status = f"âœ… Completado en {tiempo:.2f}s"
            return reporte_final, metadata, status
        
        elif response.status_code == 503:
            return """
â³ **El modelo se estÃ¡ cargando en los servidores de Hugging Face**

Por favor espera 20-30 segundos e intenta de nuevo.

(Esto solo pasa la primera vez o despuÃ©s de inactividad)
""", "", "ğŸ”„ Modelo cargando..."
        
        elif response.status_code == 401:
            return """
âŒ **Error de autenticaciÃ³n**

Tu token HF_TOKEN no es vÃ¡lido o no tiene permisos.

Verifica:
1. Que el token existe en Settings â†’ Secrets
2. Que aceptaste los tÃ©rminos en https://huggingface.co/google/medgemma-4b-it
""", "", "âŒ Error de autenticaciÃ³n"
        
        else:
            error_detail = f"""
âŒ **Error de la API de Hugging Face**

CÃ³digo: {response.status_code}
Respuesta: {response.text[:500]}

Intenta de nuevo en unos segundos.
"""
            print(f"Error API: {response.status_code} - {response.text}")
            return error_detail, "", "âŒ Error"
    
    except requests.exceptions.Timeout:
        return """
â±ï¸ **Timeout**

La solicitud tomÃ³ demasiado tiempo. Esto puede pasar si:
- El modelo estÃ¡ cargÃ¡ndose por primera vez
- Hay mucha demanda en los servidores

Por favor intenta de nuevo.
""", "", "â±ï¸ Timeout"
    
    except Exception as e:
        error_msg = f"""
âŒ **Error durante el anÃ¡lisis:**

{str(e)}

Revisa los logs del Space para mÃ¡s detalles.
"""
        print(f"âŒ Error completo: {e}")
        import traceback
        traceback.print_exc()
        return error_msg, "", "âŒ Error"

# Crear interfaz Gradio
css = """
.gradio-container {
    max-width: 1400px !important;
    margin: auto;
}
h1 {
    text-align: center;
    color: #2563eb;
}
"""

with gr.Blocks(title="MedFlow MVP", theme=gr.themes.Soft(), css=css) as demo:
    gr.Markdown("""
    # ğŸ¥ MedFlow - Producto MÃ­nimo Viable
    ## Sistema de InterpretaciÃ³n Automatizada de ImÃ¡genes MÃ©dicas
    
    **Desarrollado por:** Yeinmy Daniela Morales Barrera  
    **Modelo:** Med-GEMMA 4B (Google Health AI)  
    **Infraestructura:** Hugging Face Inference API
    
    ---
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“¤ Entrada de Datos")
            
            imagen_input = gr.Image(
                type="pil",
                label="ğŸ–¼ï¸ Imagen MÃ©dica (Rayos X, TC, etc.)",
                height=350
            )
            
            tipo_analisis = gr.Dropdown(
                choices=[
                    "DescripciÃ³n General",
                    "Hallazgos PatolÃ³gicos",
                    "Reporte Estructurado",
                    "DiagnÃ³stico Diferencial"
                ],
                value="Reporte Estructurado",
                label="ğŸ“‹ Tipo de AnÃ¡lisis"
            )
            
            idioma = gr.Radio(
                choices=["EspaÃ±ol", "InglÃ©s"],
                value="EspaÃ±ol",
                label="ğŸŒ Idioma del Reporte"
            )
            
            with gr.Row():
                procesar_btn = gr.Button("ğŸš€ Analizar Imagen", variant="primary", size="lg")
                limpiar_btn = gr.ClearButton(components=[imagen_input], value="ğŸ—‘ï¸ Limpiar", size="lg")
            
            gr.Markdown("""
            **Nota:** La primera solicitud puede tardar 30-60 segundos mientras el modelo se carga en los servidores.
            Las siguientes serÃ¡n mÃ¡s rÃ¡pidas (20-40 segundos).
            """)
        
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“‹ Resultado del AnÃ¡lisis")
            
            reporte_output = gr.Textbox(
                label="Reporte MÃ©dico Generado",
                lines=18,
                placeholder="El reporte aparecerÃ¡ aquÃ­ despuÃ©s de procesar la imagen...",
                show_copy_button=True
            )
            
            status_output = gr.Textbox(
                label="Estado del Proceso",
                lines=1,
                interactive=False
            )
    
    with gr.Accordion("ğŸ“Š Metadatos de Procesamiento", open=False):
        metadata_output = gr.Markdown()
    
    procesar_btn.click(
        fn=analizar_imagen_api,
        inputs=[imagen_input, tipo_analisis, idioma],
        outputs=[reporte_output, metadata_output, status_output]
    )
    
    gr.Markdown("""
    ---
    ### ğŸ“ InformaciÃ³n del Proyecto
    
    **Contacto:** ymoral35@estudiante.ibero.edu.co  
    **VersiÃ³n:** MVP 1.0 - API Edition
    
    *Proyecto acadÃ©mico - CorporaciÃ³n Universitaria Iberoamericana*
    """)

if __name__ == "__main__":
    demo.launch()